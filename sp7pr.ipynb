{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3741597a",
   "metadata": {},
   "source": [
    "# Megaline Subscriber Behavior Model\n",
    "\n",
    "This notebook develops a classification model to predict which new plan a subscriber should choose (Smart or Ultra) based on their usage data. The notebook performs data exploration, splits the data into training, validation, and test sets, trains several models with hyperparameter tuning, selects the best model based on validation accuracy, and finally evaluates the best model on the test set with a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d38b4a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16793dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from URL\n",
    "url = \"/workspaces/Subscriber-Behavior/users_behavior.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "711d02a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "   calls  minutes  messages   mb_used  is_ultra\n",
      "0   40.0   311.90      83.0  19915.42         0\n",
      "1   85.0   516.75      56.0  22696.96         0\n",
      "2   77.0   467.66      86.0  21060.45         0\n",
      "3  106.0   745.53      81.0   8437.39         1\n",
      "4   66.0   418.74       1.0  14502.75         0\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Quick look at the data (optional)\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "print(\"\\nData Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7796bfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our features are: calls, minutes, messages, mb_used\n",
    "# The target is is_ultra (Ultra = 1, Smart = 0)\n",
    "\n",
    "# Split the data into train, validation, and test sets.\n",
    "# First, split off the test set (20% of data) using stratification.\n",
    "train_val, test = train_test_split(df, test_size=0.20, random_state=54321, stratify=df['is_ultra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c2d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, split the remaining 80% into training (60% total) and validation (20% total).\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=54321, stratify=train_val['is_ultra'])\n",
    "# Now: train ~60%, val ~20%, test ~20%\n",
    "\n",
    "# Separate features and target for each split\n",
    "features_train = train.drop('is_ultra', axis=1)\n",
    "target_train = train['is_ultra']\n",
    "\n",
    "features_val = val.drop('is_ultra', axis=1)\n",
    "target_val = val['is_ultra']\n",
    "\n",
    "features_test = test.drop('is_ultra', axis=1)\n",
    "target_test = test['is_ultra']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b82da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables to track the best model\n",
    "best_model = None\n",
    "best_val_acc = 0\n",
    "best_model_name = None\n",
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "167e7a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=54321)\n",
    "lr_model.fit(features_train, target_train)\n",
    "lr_val_pred = lr_model.predict(features_val)\n",
    "lr_acc = accuracy_score(target_val, lr_val_pred)\n",
    "if lr_acc > best_val_acc:\n",
    "    best_model = lr_model\n",
    "    best_val_acc = lr_acc\n",
    "    best_model_name = \"LogisticRegression\"\n",
    "    best_params = lr_model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c448f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Decision Tree (tuning max_depth from 1 to 10)\n",
    "for depth in range(1, 11):\n",
    "    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=54321)\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    dt_val_pred = dt_model.predict(features_val)\n",
    "    dt_acc = accuracy_score(target_val, dt_val_pred)\n",
    "    if dt_acc > best_val_acc:\n",
    "        best_model = dt_model\n",
    "        best_val_acc = dt_acc\n",
    "        best_model_name = \"DecisionTreeClassifier\"\n",
    "        best_params = {\"max_depth\": depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ceb0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Random Forest (tuning number of trees and max_depth)\n",
    "for n_estimators in [10, 50, 100]:\n",
    "    for depth in range(2, 11):\n",
    "        rf_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=depth, random_state=54321)\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        rf_val_pred = rf_model.predict(features_val)\n",
    "        rf_acc = accuracy_score(target_val, rf_val_pred)\n",
    "        if rf_acc > best_val_acc:\n",
    "            best_model = rf_model\n",
    "            best_val_acc = rf_acc\n",
    "            best_model_name = \"RandomForestClassifier\"\n",
    "            best_params = {\"n_estimators\": n_estimators, \"max_depth\": depth}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b118b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model on the validation set:\n",
      "Model: RandomForestClassifier with parameters: {'n_estimators': 100, 'max_depth': 8}\n",
      "Validation accuracy: 0.8227060653188181\n"
     ]
    }
   ],
   "source": [
    "print(\"Best model on the validation set:\")\n",
    "print(\"Model:\", best_model_name, \"with parameters:\", best_params)\n",
    "print(\"Validation accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3059521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuracy: 0.8133748055987559\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the chosen best model on the test set\n",
    "test_pred = best_model.predict(features_test)\n",
    "test_acc = accuracy_score(target_test, test_pred)\n",
    "print(\"\\nTest accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecd8c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy (majority class): 0.6936236391912908\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: Compare with a baseline that predicts the majority class\n",
    "majority_class = target_test.mode()[0]\n",
    "baseline_pred = np.full(shape=len(target_test), fill_value=majority_class)\n",
    "baseline_acc = accuracy_score(target_test, baseline_pred)\n",
    "print(\"Baseline accuracy (majority class):\", baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039bcd27",
   "metadata": {},
   "source": [
    "### Explanation and Findings\n",
    "\n",
    "#### Data Splitting:\n",
    "We used a stratified split to ensure that each subset has a similar proportion of the two plans. The splits were approximately 60% for training, 20% for validation, and 20% for testing.\n",
    "\n",
    "#### Model Selection:\n",
    "\n",
    "We started with a logistic regression model as a baseline.\n",
    "We then trained decision trees varying the maximum depth from 1 to 10.\n",
    "Finally, we trained random forests with different numbers of trees (10, 50, 100) and maximum depths (2 to 10).\n",
    "During our search, we kept track of the best validation accuracy. You might notice that more complex models (e.g., deeper trees or more trees in the random forest) can overfit, so there is a sweet spot in terms of hyperparameters.\n",
    "\n",
    "#### Evaluation:\n",
    "Once the best model was identified based on the validation set, we evaluated its performance on the test set. Additionally, a sanity check was performed by comparing our model’s accuracy to the baseline accuracy (always predicting the majority class).\n",
    "\n",
    "#### Threshold:\n",
    "The goal was to achieve an accuracy of at least 0.75 on the test set. Adjust hyperparameters and even consider additional models (or feature engineering) if the threshold isn’t met."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
